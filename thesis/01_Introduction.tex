\chapter{Introduction}

\section{Problem Explanation}
\subsection{Device presentation}
Computer memories are designed to fit particular needs, based on their size or
latency. The memory hierarchy makes every program able to write the most accessed
data from a lower latency memory in order to access more often the smaller and
faster memory. Every time some data is not present in a lower level
memory, the system must read the higher latency one, wasting CPU cycles waiting
for the memory to complete the operation. To avoid or to mitigate this issue an
additional layer can be added. This is what happened with L3 Cache: it is
not needed for the computer to work, but to make it faster, caching more data at
the same time. \\
With the same idea Data Direct Networks developed a system that acts as a cache
between main memory and mass storage, filling the gap that there is right now.
This system is called IME, the Infinite Memory Engine.
\\ As a cache it operates in a transparent way, making every already developed
program able to run on on this platform. \\ The device can intercepts IO calls in
many ways so that its users can choose the most appropriate method for their
programs.

\subsection{The problem}
DDN IME as of now has some scaling issues when a large amount of servers are
installed. To keep data consistency, the system has to perform some transactions
from server to server. This traffic will decrease the available bandwidth for
the clients limiting the total amount of servers, hence the maximum available
cache memory. \\
Moreover inside the system are present a lot of free parameters, which will be
discussed later, that can affect performances. At the current time we are
unable to determine their optimal value. Multiple runs with different
configurations will help the investigation to the optimal configuration based on
a given architecture.

\subsection{The solution}
The solution proposed by DDN is a simulator of the system, enabling the fast
exploration of different solutions without the need to actually build many
systems. \\
Different kind of simulators exist. Below will be explained some of them:

\vspace{0.5cm}
\begin{tabular}{r | p{0.7\textwidth}}
    \textbf{Simulator} & \textbf{Details} \\ \hline
    Analytical & 
    Every event is weighted through a function and a final formula
    should lead to the result. The precision is based on the error of each
    function from the real value \\ \hline

    Trace-based &
    The simulation is based on a trace generated by the environment we
    want to simulate. The input is the result of the operations. Can take much
    storage space\\\hline

    Execution Driven &
    Instead of taking result from a trace, the simulator
    actually perform some task. Instead of taking storage space takes time
    because actions are actually performed\\\hline

    Event based & 
    Instead of simulating time passing the events are scheduled
    and called consecutively. Suitable if events do not happen regularly or at a
    regular interval\\\hline
    
    Discrete Event & 
    Time evolve by 'hop'. The clock of the system is increased when an event
    occurs. The completion of an event is defined by a transition function. The
    flow of event is defined by a finite state diagram.

    Time is split in small units. As an event happens, there is
    a change of state in the system following a finite state machine
    diagram.\\\hline

    Continuous Event & 
    Time is continuous in contrast with discrete event simulator.
\end{tabular}
\vspace{0.5cm}

From these simulator, the most suitable for the case is the \textbf{Discrete
Event Simulator}. The analytical simulator is suitable for an environment where
some events can be parametrized, but IME is a complex environment with resources
and network fabric that can be busy when required. \\
For trace-based and execution driven are required both data and machine
configuration and none of them are available since IME is a new hardware. \\
Event based simulation can represent better the environment, more precisely a
discrete event simulator is more effective since is not needed a continuous time
space, avoiding rounding errors due to binary representation.

%Since a simulation is a work from scratch, will need also the
%implementation of some tools to monitor the load of the system over time to
%check the quality and the performance of the model. \\
%Moreover, will be simulated also systematic failures since these happens in real
%world and the system already is able to recover some fatal errors on its own.

\section{Requirements Analysis}\label{requirements}
Simulators are not necessarily computationally intensive applications. The
computational complexity depend on the accuracy of the environment to be
simulated. In this case the simulation of network transactions will end up in
waiting an amount of simulation time based on a formula. 
Such approach allows to focus on flexibility, where the system can easily evolve
on by a component basis. For instance a more accurate model can be implemented
if it appear that the modeling of the communication layer is injecting too much
noise.
Following the principle of "Not reinventing the wheel" the project has started
using a library for discrete simulation. This
accelerated the project since at this point only the logic of the system has to
be implemented. After the development part will come the investigation phase to
better understand every free parameter inside the system.
To list the requirements, these are:
\begin{itemize}
    \item environment focused on flexibility
    \item compatible simulation library
    \item monitor tools to inspect the system performances
    \item test-suite for the simulated system 
\end{itemize}

Every good practice about software design and development is implicit in this
list.

\subsection{HPC Relevance}
The simulator by itself is not the product relevant from the HPC point of view.
What is relevant instead is the problem it is going to solve: there is already a
problem of scalability of a product and the simulator should solve or help to
solve it faster than a traditional development process would. This will accelerate
architecture and configuration investigation.

\section{Development environment}
To satisfy the requirements we chose Python because of its flexibility and
an already implemented library. This platform is well suited  to create many
models, focusing the attention on the system architecture instead of low level
details. \\
The simulation library chosen is SimPy \cite{simpy}, a discrete events
simulation library. It is well maintained and perfectly integrated with
language. \\
A drawback of a Python environment is its dynamic types: this is not a problem
in general but one of the main features of python instead that makes it one of
the best scripting language. Anyway for bigger projects a safe type checking
helps the development. The lack of this checking by design slowed down the
development at the beginning.

\section{SimPy}
This discrete event simulation library is \textit{Events} oriented. An event can
be processed and can be represented as a function performing some general
action, based on the situation. The caller event can wait for the completion of
the task called or just trigger it and simulate an async call. This make a
simulation of a multithreaded environment really simple using a few lines of
code. \\
More details on this library will be explained later, in section \ref{simpy}

