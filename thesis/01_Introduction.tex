\chapter{Introduction}

\section{Problem Explanation}
\subsection{Device presentation}
Computer memories are designed to fit particular needs, based on their size or
latency. The memory hierarchy make every program able to write the most accessed
data in la lower latency memory in order to access the most the smaller and
lower latency memory. Every time some data is not present in a lower level
memory, the system must read the higher latency one, wasting CPU cycles waiting
for the memory to complete the operation. To avoid or to mitigate this issue, an
additional memory layer can be added. This is what happened with L3 Cache: it is
not needed for the computer to work, but make it faster, caching more data at
the same time. \\
With the same idea Data Direct Networks developed a device that act as a cache
between main memory and mass storage, filling the gap that there is right now.
\\ As a cache, it operates in a transparent way, making every already developed
program able to run on on this platform. \\ The device can intercept IO calls in
many ways, so its users can choose the method most appropriate method for
themselves.

\subsection{The problem}
The system as of now has some scaling issue when a large amount of servers are
installed. To keep data consistency, the system has to perform some transactions
from server to server. This traffic will decrease the performance of the
clients traffic. This limits the amount of servers and with this also the amount
of cache data available. \\
Moreover inside the system are present a lot of free parameters, which will be
discussed later, that can affect performances. At the current time we are
unable to determine their optimal value. Multiple runs with different
configurations will help the investigation to the optimal configuration given an
architecture.

\subsection{The solution}
The solution proposed by DDN is a simulator of the system, enabling the fast
exploration of different solutions without the need to actually build many
systems. \\
Different kind of simulators exist. Below will be explained some of them:

\vspace{0.5cm}
\begin{tabular}{r | p{0.7\textwidth}}
    \textbf{Simulator} & \textbf{Details} \\ \hline
    Analytical & 
    Every event is weighted through a function and a final formula
    should lead to the result. The precision is based on the error of each
    function from the real value \\ \hline

    Trace-based &
    The simulation is based on a trace generated by the environment we
    want to simulate. The input is the result of the operations. Can take much
    storage space\\\hline

    Execution Driven &
    Instead of taking result from a trace, the simulator
    actually perform some task. Instead of taking storage space takes time
    because actions are actually performed\\\hline

    Event based & 
    Instead of simulating time passing the events are scheduled
    and called consecutively. Suitable if events do not happen regularly or at a
    regular interval\\\hline
    
    Discrete Event & 
    Time evolve by 'hop'. The clock of the system is increased when an event
    occurs. The completion of an event is defined by a transition function. The
    flow of event is defined by a finite state diagram.

    Time is split in small units. As an event happens, there is
    a change of state in the system following a finite state machine
    diagram.\\\hline

    Continuous Event & 
    Time is continuous in contrast with discrete event simulator.
\end{tabular}
\vspace{0.5cm}

From these simulator, the most suitable for the case is the \textbf{Discrete
Event Simulator}. The analytical simulator is suitable for an environment where
some events can be parametrized, but IME is a complex environment with resources
and network fabric that can be busy when required. \\
For trace-based and execution driven is required data and machine configuration
and none of them are available since IME is a new hardware. \\
Event based simulation can represent better the environment, more precisely a
discrete event simulator is more effective since is not needed a continuous time
space, avoiding rounding errors due to binary representation.

%Since a simulation is a work from scratch, will need also the
%implementation of some tools to monitor the load of the system over time to
%check the quality and the performance of the model. \\
%Moreover, will be simulated also systematic failures since these happens in real
%world and the system already is able to recover some fatal errors on its own.

\section{Requirements Analysis}\label{requirements}
Simulators are not necessarily computationally intensive applications. The
computational complexity depend on the accuracy of the environment to be
simulated. In this case the simulation of network transactions will end up in
waiting an amount of simulation time based on a formula. 
Such approach allows to focus on flexibility, where the system can easily evolve
on by a component basis. For instance a more accurate model can be implemented
if it appear that the modeling of the communication layer is injecting too much
noise.
Following the principle of "Not reinventing the wheel" the project has started
using a library for discrete simulation. This
accelerated the project since at this point only the logic of the system has to
be implemented. After the development part will come the investigation phase to
better understand every free parameter inside the system.
To list the requirements, these are:
\begin{itemize}
    \item environment focused on flexibility
    \item compatible simulation library
    \item monitor tools to inspect the system performances
    \item test-suite for the simulated system 
\end{itemize}

Every good practice about software design and development is implicit in this
list.

\subsection{HPC Relevance}
The simulator by itself is not the product relevant from the HPC point of view.
What is relevant instead is the problem it is going to solve: there is already a
problem of scalability of a product and the simulator should solve or help to
solve it faster than traditional development process would. This will accelerate
architecture and configuration investigation.

\section{Development environment}
To satisfy the stated requirements has been chosen to develop the project in Python
because of its flexibility and to create many models, focusing the attention on the
system architecture instead of low level details. \\
The simulation library chosen is SimPy \cite{simpy}, a discrete events
simulation library. It is well maintained and perfectly integrated with
language. \\
A drawback of a Python environment is its dynamic types: this is not a problem
in general but one of the main features of python instead, that makes it one of
the best scripting language. But for bigger projects the requirements from the
changes and type checking protect us against implementation errors. From version
3.5 the language allows \textit{Type annotations} that doesn't prevent the
developer from using different data types but integrated with a modern IDE, it
will suggest before running the program the potential issues, speeding up
development.

\section{SimPy}
This discrete event simulation library is \textit{Events oriented}. An event can
be processed and can be represented ad a function performing some general
action, based on the situation. The caller event can wait for the completion of
the task called or just trigger it and simulate an async call. This make a
simulation of a multithreaded environment really simple and few lines of code
are required for the simulation to work. \\
More details on this library will be explained later, in section \ref{simpy}

